{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from gym.wrappers import Monitor\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import math\n",
    "import copy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CartPoleAgent(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CartPoleAgent, self).__init__()\n",
    "        self.affine1 = nn.Linear(4, 124)\n",
    "        # self.dropout = nn.Dropout(p=0.6)\n",
    "        self.affine2 = nn.Linear(124, 2)\n",
    "\n",
    "        self.saved_log_probs = []\n",
    "        self.rewards = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.affine1(x)\n",
    "        # x = self.dropout(x)\n",
    "        x = F.relu(x)\n",
    "        action_scores = self.affine2(x)\n",
    "        return F.softmax(action_scores, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old code assuming random initialization\n",
    "\n",
    "def init_weights(m):\n",
    "    if ((type(m) == nn.Linear) | (type(m) == nn.Conv2d)):\n",
    "        torch.nn.init.xavier_uniform(m.weight)\n",
    "        m.bias.data.fill_(0.00)\n",
    "\n",
    "def return_random_agents(num_agents):\n",
    "    agents = []\n",
    "    for _ in range(num_agents):\n",
    "        \n",
    "        agent = CartPoleAI()\n",
    "        \n",
    "        for param in agent.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        init_weights(agent)\n",
    "        agents.append(agent)\n",
    "        \n",
    "    return agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CartPoleAgent(\n",
       "   (affine1): Linear(in_features=4, out_features=124, bias=True)\n",
       "   (affine2): Linear(in_features=124, out_features=2, bias=True)\n",
       " ), CartPoleAgent(\n",
       "   (affine1): Linear(in_features=4, out_features=124, bias=True)\n",
       "   (affine2): Linear(in_features=124, out_features=2, bias=True)\n",
       " ), CartPoleAgent(\n",
       "   (affine1): Linear(in_features=4, out_features=124, bias=True)\n",
       "   (affine2): Linear(in_features=124, out_features=2, bias=True)\n",
       " ), CartPoleAgent(\n",
       "   (affine1): Linear(in_features=4, out_features=124, bias=True)\n",
       "   (affine2): Linear(in_features=124, out_features=2, bias=True)\n",
       " ), CartPoleAgent(\n",
       "   (affine1): Linear(in_features=4, out_features=124, bias=True)\n",
       "   (affine2): Linear(in_features=124, out_features=2, bias=True)\n",
       " )]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_initialized_agents(dir='../models'):\n",
    "    agents = []\n",
    "    for path in os.listdir(dir):\n",
    "        if path[-4:] == '.pth':\n",
    "            try:\n",
    "                model = CartPoleAgent()\n",
    "                model.load_state_dict(torch.load(dir + '/' + path))\n",
    "                agents.append(model)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    return agents\n",
    "\n",
    "get_initialized_agents('../models20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agents(agents):\n",
    "    reward_agents = []\n",
    "    env = gym.make(\"CartPole-v1\")\n",
    "    env.spec.reward_threshold = 500\n",
    "    \n",
    "    for agent in agents:\n",
    "        agent.eval()\n",
    "    \n",
    "        observation = env.reset()\n",
    "        \n",
    "        r, s = 0, 0\n",
    "        for _ in range(250):\n",
    "            \n",
    "            inp = torch.tensor(observation).type('torch.FloatTensor').view(1,-1)\n",
    "            output_probabilities = agent(inp).detach().numpy()[0]\n",
    "            action = np.random.choice(range(game_actions), 1, p=output_probabilities).item()\n",
    "            new_observation, reward, done, info = env.step(action)\n",
    "            r = r + reward\n",
    "            \n",
    "            s = s + 1\n",
    "            observation = new_observation\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        reward_agents.append(r)        \n",
    "        # reward_agents.append(s)\n",
    "    \n",
    "    return reward_agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_average_score(agent, runs):\n",
    "    score = 0.\n",
    "    for i in range(runs):\n",
    "        score += run_agents([agent])[0]\n",
    "    return score / runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agents_n_times(agents, runs):\n",
    "    return [return_average_score(agent, runs) for agent in agents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate(agent):\n",
    "    child_agent = copy.deepcopy(agent)\n",
    "    mutation_power = 0.02 # Set from https://arxiv.org/pdf/1712.06567.pdf\n",
    "    for param in child_agent.parameters():\n",
    "        if len(param.shape) == 4: # Weights of Conv2D\n",
    "            for i0 in range(param.shape[0]):\n",
    "                for i1 in range(param.shape[1]):\n",
    "                    for i2 in range(param.shape[2]):\n",
    "                        for i3 in range(param.shape[3]):\n",
    "                            param[i0][i1][i2][i3] += mutation_power * np.random.randn()\n",
    "        \n",
    "        elif len(param.shape) == 2: # Weights of linear layer\n",
    "            for i0 in range(param.shape[0]):\n",
    "                for i1 in range(param.shape[1]):\n",
    "                    param[i0][i1] += mutation_power * np.random.randn()\n",
    "        \n",
    "        elif len(param.shape) == 1: # Biases of linear layer or conv layer\n",
    "            for i0 in range(param.shape[0]):\n",
    "                \n",
    "                param[i0] += mutation_power * np.random.randn()\n",
    "\n",
    "    return child_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_children(agents, sorted_parent_indexes, elite_index):\n",
    "    children_agents = []\n",
    "    \n",
    "    for i in range(len(agents)-1):\n",
    "        selected_agent_index = sorted_parent_indexes[np.random.randint(len(sorted_parent_indexes))]\n",
    "        children_agents.append(mutate(agents[selected_agent_index]))\n",
    "\n",
    "    elite_child = add_elite(agents, sorted_parent_indexes, elite_index)\n",
    "    children_agents.append(elite_child)\n",
    "    elite_index = len(children_agents) - 1\n",
    "    \n",
    "    return children_agents, elite_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_elite(agents, sorted_parent_indexes, elite_index=None, only_consider_top_n=10):\n",
    "    candidate_elite_index = sorted_parent_indexes[:only_consider_top_n]\n",
    "    \n",
    "    if elite_index is not None:\n",
    "        candidate_elite_index = np.append(candidate_elite_index,[elite_index])\n",
    "        \n",
    "    top_score = None\n",
    "    top_elite_index = None\n",
    "    \n",
    "    for i in candidate_elite_index:\n",
    "        score = return_average_score(agents[i],runs=5)\n",
    "        print(\"Score for elite i \", i, \" is \", score)\n",
    "        \n",
    "        if(top_score is None):\n",
    "            top_score = score\n",
    "            top_elite_index = i\n",
    "        elif(score > top_score):\n",
    "            top_score = score\n",
    "            top_elite_index = i\n",
    "            \n",
    "    print(\"Elite selected with index \",top_elite_index, \" and score\", top_score)\n",
    "    \n",
    "    child_agent = copy.deepcopy(agents[top_elite_index])\n",
    "    return child_agent\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generation  0  | Mean rewards:  84.66  | Mean of top 5:  84.66\n",
      "Top  5  scores [4 0 1 3 2]\n",
      "Rewards for top:  [130.9, 94.5, 85.1, 59.3, 53.5]\n",
      "Score for elite i  4  is  178.6\n",
      "Score for elite i  0  is  96.0\n",
      "Score for elite i  1  is  114.4\n",
      "Score for elite i  3  is  68.2\n",
      "Score for elite i  2  is  55.6\n",
      "Elite selected with index  4  and score 178.6\n",
      "\n",
      "\n",
      "Generation  1  | Mean rewards:  87.28  | Mean of top 5:  87.28\n",
      "Top  5  scores [4 2 3 0 1]\n",
      "Rewards for top:  [142.0, 86.8, 81.7, 76.1, 49.8]\n",
      "Score for elite i  4  is  153.4\n",
      "Score for elite i  2  is  46.4\n",
      "Score for elite i  3  is  63.0\n",
      "Score for elite i  0  is  75.2\n",
      "Score for elite i  1  is  63.2\n",
      "Score for elite i  4  is  107.4\n",
      "Elite selected with index  4  and score 153.4\n",
      "\n",
      "\n",
      "Generation  2  | Mean rewards:  90.2  | Mean of top 5:  90.2\n",
      "Top  5  scores [4 2 0 3 1]\n",
      "Rewards for top:  [144.6, 85.9, 81.3, 75.1, 64.1]\n",
      "Score for elite i  4  is  139.2\n",
      "Score for elite i  2  is  80.8\n",
      "Score for elite i  0  is  50.8\n",
      "Score for elite i  3  is  81.2\n",
      "Score for elite i  1  is  64.0\n",
      "Score for elite i  4  is  156.4\n",
      "Elite selected with index  4  and score 156.4\n",
      "\n",
      "\n",
      "Generation  3  | Mean rewards:  98.74000000000001  | Mean of top 5:  98.73999999999998\n",
      "Top  5  scores [1 4 2 3 0]\n",
      "Rewards for top:  [154.8, 154.6, 68.9, 61.0, 54.4]\n",
      "Score for elite i  1  is  122.2\n",
      "Score for elite i  4  is  173.2\n",
      "Score for elite i  2  is  81.6\n",
      "Score for elite i  3  is  70.8\n",
      "Score for elite i  0  is  54.0\n",
      "Score for elite i  4  is  176.2\n",
      "Elite selected with index  4  and score 176.2\n",
      "\n",
      "\n",
      "Generation  4  | Mean rewards:  101.3  | Mean of top 5:  101.3\n",
      "Top  5  scores [4 1 0 2 3]\n",
      "Rewards for top:  [160.6, 159.4, 69.7, 61.2, 55.6]\n",
      "Score for elite i  4  is  152.6\n",
      "Score for elite i  1  is  178.0\n",
      "Score for elite i  0  is  90.6\n",
      "Score for elite i  2  is  77.6\n",
      "Score for elite i  3  is  59.8\n",
      "Score for elite i  4  is  142.8\n",
      "Elite selected with index  1  and score 178.0\n"
     ]
    }
   ],
   "source": [
    "game_actions = 2\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "agents = get_initialized_agents('../models40')\n",
    "# agents = return_random_agents(5)\n",
    "\n",
    "top_limit = 5 # Number of top agents to consider as parents\n",
    "generations = 5\n",
    "\n",
    "elite_index = None\n",
    "for generation in range(generations):\n",
    "    rewards = run_agents_n_times(agents, 10) # Average of k runs\n",
    "\n",
    "    sorted_parent_indexes = np.argsort(rewards)[::-1][:top_limit]\n",
    "    print('\\n')\n",
    "    \n",
    "    top_rewards = []\n",
    "    for best_parent in sorted_parent_indexes:\n",
    "        top_rewards.append(rewards[best_parent])\n",
    "    \n",
    "    print(\"Generation \", generation, \" | Mean rewards: \", np.mean(rewards), \" | Mean of top 5: \",np.mean(top_rewards[:5]))\n",
    "    # print(rewards)\n",
    "    print(\"Top \",top_limit,\" scores\", sorted_parent_indexes)\n",
    "    print(\"Rewards for top: \",top_rewards)\n",
    "    \n",
    "    children_agents, elite_index = return_children(agents, sorted_parent_indexes, elite_index)\n",
    "    agents = children_agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_agent(agent):\n",
    "    try:\n",
    "        env = gym.make(\"CartPole-v1\")\n",
    "        \n",
    "        env_record = Monitor(env, './video', force=True)\n",
    "        observation = env_record.reset()\n",
    "        last_observation = observation\n",
    "        \n",
    "        r = 0\n",
    "        for _ in range(250):\n",
    "            env_record.render()\n",
    "            inp = torch.tensor(observation).type('torch.FloatTensor').view(1,-1)\n",
    "            output_probabilities = agent(inp).detach().numpy()[0]\n",
    "            action = np.random.choice(range(game_actions), 1, p=output_probabilities).item()\n",
    "            new_observation, reward, done, info = env_record.step(action)\n",
    "            r=r+reward\n",
    "            observation = new_observation\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        env_record.close()\n",
    "        print(\"Rewards: \", r)\n",
    "\n",
    "    except Exception as e:\n",
    "        env_record.close()\n",
    "        print(e.__doc__)\n",
    "        print(e.message)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rewards:  200.0\n"
     ]
    }
   ],
   "source": [
    "play_agent(agents[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
